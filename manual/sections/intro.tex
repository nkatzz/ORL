\section{Introduction}
\label{sec:intro}

This document is intended to be used as a manual for \trail, a software package that provides a common interface to a number of \& algorithms for Temporal Relational Theory Learning. These algorithms are designed for learning logical theories from data of temporal nature, based on techniques from the fields of Inductive Logic Programming (ILP) \cite{de2008logical} \& Statistical Relational Learning (SRL) \cite{raedt2016statistical}. The learnt models may be used for reasoning with time \& events, in applications such as Complex Event Recognition (CER) \cite{cugola2012processing}. 

CER systems detect occurrences of \emph{complex events} in streaming input, defined as spatio-temporal combinations of \emph{simple events} (e.g. sensor data), using a set of complex event patterns. Since such patterns are not always known beforehand, while existing ones may frequently need to be updated to reflect change in the incoming data characteristics, machine learning algorithms for discovering such patterns from data are highly useful. Several challenges are involved in this type of learning. Scalability is a major requirement, since data collected in applications of temporal nature usually come in large volumes, or even in open-ended data streams. Also, such algorithms should be resilient to noise \& uncertainty, which are ubiquitous in temporal data sources \cite{DBLP:journals/corr/AlevizosSAP17}, while taking into account commonsense phenomena \cite{mueller2014commonsense}, which often characterize dynamic application domains. Finally, Valuable existing expert knowledge about the domain may greatly facilitate learning \& reasoning for CER if taken into account. This calls for expressive, yet highly efficient from an operational perspective, event pattern specification languages that allow to easily encode domain principles into usable background knowledge for learning \& reasoning. 

The learning algorithms contained in \trail \ attempt to address some of these challenges. Following work in logic-based approaches to CER \cite{artikis2012logic,artikis2015event}, which use first-order logic as a unifying representation language for events, complex event patterns and background knowledge, \trail \ is also based on logic. This allows for direct connections to machine learning techniques from the fields of ILP and SRL. A lot of work behind most of the learning algorithms in \trail \ has been devoted to scalability, with a focus on theory revision techniques, incremental \& online learning.\\

\noindent The following algorithms are implemented in \trail:

\begin{itemize}
	\item \learnrev, which is based on ideas from non-monotonic ILP and incorporates machinery from the \xhail \ \cite{ray2009nonmonotonic} algorithm, in addition to theory revision techniques. \learnrev \ operates in a ``one-shot'' mode, generalizing from a (typically small) excerpt of data, representative of some application domain. \learnrev \ is able to either learn a theory from scratch or revise an existing one.
	
	\item \iled, originally introduced in \cite{katzouris2015incremental}, an algorithm that lifts the non-monotonic learning \& theory revision techniques on which \learnrev \ relies to an incremental learning setting, in order to foster scalability. \iled \ learns incrementally, by iteratively processing small data ``snapshots'' (each such snapshot may be e.g. a small data chunk that \learnrev \ uses for one-shot learning). The \iled \ algorithm introduced in \cite{katzouris2015incremental} was designed for learning sound hypotheses (i.e. theories that correctly account for the entirety of the training data). It is thus not capable to deal with noise, which often makes it less useful in real-life applications. In contrast, although closely related to the original \iled \ algorithm, the  \iled \ version  included in \trail \ abandons the requirement for soundness and instead attempts to learn a theory that minimizes the training error, using theory revision techniques and an iterative hill-climbing search in the space of theories. 
	\item \oled, an algorithm introduced in \cite{DBLP:journals/tplp/KatzourisAP16}, which learns logical theories in an online fashion, i.e. in a single-pass over a training set. 
	
	\item \woled, an algorithm introduced in \cite{kr2020}, which learns learns rules' structure \& weights in an online fashion. \woled \ is also capable of probabilistic inference with the weighted rules.     
\end{itemize} 

\noindent \trail \ is based on Answer Set Programming (ASP) \cite{lifschitz2019answer} and all learning algorithms contained in this software package rely on the \clingo\footnote{\url{https://potassco.org/clingo/}} \ \cite{gebser2015potassco} answer set solver. 

This document contains some material on Inductive Logic Programming, Statistical Relational Learning and Answer Set Programming, but it is by no means an adequate introduction to any of these fields. The interested reader should refer to (e.g.) the books on these topics mentioned above (\cite{de2008logical,raedt2016statistical,lifschitz2019answer}), or to some other of the numerous resources that are available. The research papers mentioned earlier (and in what follows in this document) may also be helpful. More resources on CER may be found at the website of NCSR's Complex Event Recognition group\footnote{\url{http://cer.iit.demokritos.gr/}}. \textbf{All examples used throughout this document may be downloaded from...}  

The rest of the document is structured as follows: In Section...
